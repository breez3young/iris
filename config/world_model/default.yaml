_target_: models.TransformerConfig
tokens_per_block: 17 # obs每一帧的token数+action的token数，因为action是离散的，用一个数字即可，所以 16 + 1
max_blocks: 20 # 可以认为是world model imagined sequence length
attention: 'causal'
num_layers: 10
num_heads: 4
embed_dim: 256 # 这里跟tokenizer里面的embedding维度不一样
embed_pdrop: 0.1
resid_pdrop: 0.1
attn_pdrop: 0.1
